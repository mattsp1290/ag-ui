# Enterprise Monitoring Integration

This package provides enterprise-grade monitoring capabilities for the AG-UI event validation system, building upon the existing `ValidationPerformanceMetrics` with enhanced observability features.

## Features

### 1. Prometheus Integration
- **Custom Collectors**: Specialized collectors for event validation, rule execution, SLA compliance, and memory usage
- **Rich Metrics**: Comprehensive metrics with custom labels and multi-dimensional analysis
- **Health Endpoints**: `/health` and `/ready` endpoints for container orchestration
- **Optimized Export**: Efficient metric updates with configurable intervals

### 2. OpenTelemetry Enhancement
- **Distributed Tracing**: Full trace context propagation for event and rule execution
- **Custom Attributes**: Rich span attributes for debugging and analysis
- **OTLP Export**: Native OTLP/gRPC exporter with header support
- **Resource Metadata**: Service name, version, and environment tagging

### 3. Grafana Dashboard Generation
- **Auto-Generated Dashboards**: Four pre-configured dashboards for different use cases
- **Dynamic Updates**: Automatic dashboard regeneration based on metric changes
- **API Integration**: Direct upload to Grafana via API
- **Custom Panels**: Specialized visualizations for event validation metrics

### 4. Alert Management
- **Rule-Based Alerts**: Configurable alert rules with thresholds
- **Alert Severity**: Multi-level severity (critical, high, medium, low, info)
- **Webhook Integration**: External notification support
- **Alert History**: Historical tracking of alert lifecycle
- **Runbook Integration**: Automatic runbook linking for each alert type

### 5. SLA Monitoring
- **Configurable Targets**: Define custom SLA targets for latency, throughput, and error rate
- **Real-Time Tracking**: Continuous SLA compliance monitoring
- **Trend Analysis**: Historical trend detection (up, down, stable)
- **Violation Alerts**: Automatic alerting on SLA breaches

## Usage

### Basic Setup

```go
import "github.com/mattsp1290/ag-ui/go-sdk/pkg/core/events/monitoring"

// Create monitoring integration with default config
monitor, err := monitoring.NewMonitoringIntegration(nil)
if err != nil {
    log.Fatal(err)
}
defer monitor.Shutdown()

// Record events with enhanced context
ctx := context.Background()
monitor.RecordEventWithContext(ctx, 50*time.Millisecond, true, map[string]string{
    "event_type": "user_action",
    "source": "web",
})
```

### Custom Configuration

```go
config := &monitoring.Config{
    MetricsConfig: events.ProductionMetricsConfig(),
    PrometheusPort: 9090,
    PrometheusPath: "/metrics",
    EnableCustomLabels: true,
    CustomLabels: map[string]string{
        "datacenter": "us-east-1",
        "environment": "production",
    },
    
    // OpenTelemetry settings
    OTLPEndpoint: "otel-collector.monitoring:4317",
    TraceSampleRate: 0.1,
    ServiceName: "event-validator",
    ServiceVersion: "2.0.0",
    
    // Alert configuration
    AlertWebhookURL: "https://alerts.example.com/webhook",
    AlertThresholds: monitoring.AlertThresholds{
        ErrorRatePercent: 5.0,
        LatencyP99Millis: 100.0,
        MemoryUsagePercent: 80.0,
    },
    
    // SLA targets
    SLATargets: map[string]monitoring.SLATarget{
        "validation_latency": {
            Name: "Event Validation Latency",
            TargetValue: 50.0,
            Unit: "milliseconds",
            AlertOnViolation: true,
        },
    },
    
    // Grafana integration
    GrafanaURL: "https://grafana.example.com",
    GrafanaAPIKey: "your-api-key",
    AutoGenerateDash: true,
}

monitor, err := monitoring.NewMonitoringIntegration(config)
```

### Accessing Metrics

```go
// Get enhanced dashboard data
dashboard := monitor.GetEnhancedDashboardData()

// Access SLA status
for name, status := range dashboard.SLAStatus {
    fmt.Printf("SLA %s: %.2f%s (target: %.2f%s)\n", 
        name, 
        status.CurrentValue, 
        status.Target.Unit,
        status.Target.TargetValue,
        status.Target.Unit,
    )
}

// Check active alerts
for _, alert := range dashboard.ActiveAlerts {
    fmt.Printf("ALERT: %s - %s (severity: %s)\n", 
        alert.Name, 
        alert.Description, 
        alert.Severity,
    )
}
```

## Prometheus Metrics

### Standard Metrics
- `ag_ui_events_validation_total`: Total event validations (counter)
- `ag_ui_events_validation_duration_seconds`: Validation duration histogram
- `ag_ui_events_validation_errors_total`: Total validation errors
- `ag_ui_events_throughput_events_per_second`: Current throughput gauge
- `ag_ui_events_memory_usage_bytes`: Memory usage by type

### Custom Collectors
- `ag_ui_event_validation_rate`: Real-time validation rate
- `ag_ui_rule_execution_count`: Per-rule execution counts
- `ag_ui_rule_avg_duration`: Average duration per rule
- `ag_ui_sla_compliance`: SLA compliance status (0 or 1)
- `ag_ui_memory_allocated_bytes`: Current allocated memory

## Grafana Dashboards

### 1. Event Validation Overview
- Key metrics (total events, error rate, throughput, SLA)
- Time series for event processing rate and latency percentiles
- Top slow rules table
- Rule execution heatmap

### 2. Rule Performance Analysis
- Per-rule execution metrics
- Duration trends over time
- Error rate by rule
- Configurable rule filtering

### 3. SLA Compliance Monitoring
- SLA status table with current values
- Trend graphs for each SLA target
- Violation tracking
- At-risk SLA identification

### 4. System Health Monitor
- Memory usage trends
- GC activity monitoring
- Active alerts list
- Recent warning logs

## Alert Rules

### Pre-configured Alerts

1. **High Error Rate**: Triggers when error rate exceeds threshold
2. **High Latency**: P99 latency exceeds configured limit
3. **Memory Pressure**: Memory usage critically high
4. **Low Throughput**: Processing rate below minimum
5. **Slow Rule Execution**: Individual rules exceeding time limits
6. **SLA Violation**: Any SLA target breached

### Runbook Integration

Each alert includes:
- Detailed description
- Severity level
- Direct runbook link
- Step-by-step remediation guide

Example runbook steps for high error rate:
1. Check application logs for error patterns
2. Verify upstream dependencies are healthy
3. Check for recent deployments or configuration changes
4. Scale up if load-related
5. Rollback if deployment-related

## Performance Considerations

- **Sampling**: Configurable sampling rate to reduce overhead
- **Batch Updates**: Metrics are batched for efficient export
- **Ring Buffer**: Fixed-size memory history to prevent unbounded growth
- **Optimized GC Stats**: Cached GC statistics to reduce collection overhead
- **Concurrent Safe**: All operations are thread-safe for high-throughput scenarios

## Testing

Comprehensive test coverage including:
- Unit tests for all components
- Integration tests with real metrics
- Performance benchmarks
- Concurrent operation testing
- Memory leak detection tests

Run tests:
```bash
go test -v ./go-sdk/pkg/core/events/monitoring/...
```

Run benchmarks:
```bash
go test -bench=. ./go-sdk/pkg/core/events/monitoring/...
```

## Compatibility

Fully compatible with the existing `ValidationPerformanceMetrics` system. The monitoring integration wraps and enhances the base metrics collector without breaking existing functionality.