package encoding

import (
	"context"
	"fmt"
	"runtime"
	"testing"
	"time"

	"github.com/ag-ui/go-sdk/pkg/core/events"
	"github.com/ag-ui/go-sdk/pkg/encoding/json"
	"github.com/ag-ui/go-sdk/pkg/encoding/protobuf"
)

// createTestEvents creates a slice of test events
func createTestEvents(count int) []events.Event {
	events := make([]events.Event, count)
	for i := 0; i < count; i++ {
		events[i] = &events.TextMessageContentEvent{
			BaseEvent: &events.BaseEvent{
				EventType: events.EventTypeTextMessageContent,
			},
			MessageID: fmt.Sprintf("message_%d", i),
			Delta:     fmt.Sprintf("Test content %d", i),
		}
	}
	return events
}

// BenchmarkJSONEncodingWithoutPool benchmarks JSON encoding without pooling
func BenchmarkJSONEncodingWithoutPool(b *testing.B) {
	ctx := context.Background()
	testEvents := createTestEvents(100)
	
	b.ResetTimer()
	b.ReportAllocs()
	
	for i := 0; i < b.N; i++ {
		encoder := json.NewJSONEncoder(&EncodingOptions{})
		for _, event := range testEvents {
			_, err := encoder.Encode(ctx, event)
			if err != nil {
				b.Fatal(err)
			}
		}
	}
}

// BenchmarkJSONEncodingWithPool benchmarks JSON encoding with pooling
func BenchmarkJSONEncodingWithPool(b *testing.B) {
	ctx := context.Background()
	testEvents := createTestEvents(100)
	factory := NewPooledCodecFactory()
	
	b.ResetTimer()
	b.ReportAllocs()
	
	for i := 0; i < b.N; i++ {
		encoder, err := factory.CreateEncoder(ctx, "application/json", &EncodingOptions{})
		if err != nil {
			b.Fatal(err)
		}
		
		for _, event := range testEvents {
			_, err := encoder.Encode(ctx, event)
			if err != nil {
				b.Fatal(err)
			}
		}
		
		if pooledEncoder, ok := encoder.(ReleasableEncoder); ok {
			pooledEncoder.Release()
		}
	}
}

// BenchmarkJSONDecodingWithoutPool benchmarks JSON decoding without pooling
func BenchmarkJSONDecodingWithoutPool(b *testing.B) {
	ctx := context.Background()
	testEvents := createTestEvents(100)
	
	// Pre-encode events for decoding
	encoder := json.NewJSONEncoder(&EncodingOptions{})
	encodedEvents := make([][]byte, len(testEvents))
	for i, event := range testEvents {
		data, err := encoder.Encode(ctx, event)
		if err != nil {
			b.Fatal(err)
		}
		encodedEvents[i] = data
	}
	
	b.ResetTimer()
	b.ReportAllocs()
	
	for i := 0; i < b.N; i++ {
		decoder := json.NewJSONDecoder(&DecodingOptions{})
		for _, data := range encodedEvents {
			_, err := decoder.Decode(ctx, data)
			if err != nil {
				b.Fatal(err)
			}
		}
	}
}

// BenchmarkJSONDecodingWithPool benchmarks JSON decoding with pooling
func BenchmarkJSONDecodingWithPool(b *testing.B) {
	ctx := context.Background()
	testEvents := createTestEvents(100)
	factory := NewPooledCodecFactory()
	
	// Pre-encode events for decoding
	encoder := json.NewJSONEncoder(&EncodingOptions{})
	encodedEvents := make([][]byte, len(testEvents))
	for i, event := range testEvents {
		data, err := encoder.Encode(ctx, event)
		if err != nil {
			b.Fatal(err)
		}
		encodedEvents[i] = data
	}
	
	b.ResetTimer()
	b.ReportAllocs()
	
	for i := 0; i < b.N; i++ {
		decoder, err := factory.CreateDecoder(ctx, "application/json", &DecodingOptions{})
		if err != nil {
			b.Fatal(err)
		}
		
		for _, data := range encodedEvents {
			_, err := decoder.Decode(ctx, data)
			if err != nil {
				b.Fatal(err)
			}
		}
		
		if pooledDecoder, ok := decoder.(ReleasableDecoder); ok {
			pooledDecoder.Release()
		}
	}
}

// BenchmarkProtobufEncodingWithoutPool benchmarks Protobuf encoding without pooling
func BenchmarkProtobufEncodingWithoutPool(b *testing.B) {
	ctx := context.Background()
	testEvents := createTestEvents(100)
	
	b.ResetTimer()
	b.ReportAllocs()
	
	for i := 0; i < b.N; i++ {
		encoder := protobuf.NewProtobufEncoder(&EncodingOptions{})
		for _, event := range testEvents {
			_, err := encoder.Encode(ctx, event)
			if err != nil {
				b.Fatal(err)
			}
		}
	}
}

// BenchmarkProtobufEncodingWithPool benchmarks Protobuf encoding with pooling
func BenchmarkProtobufEncodingWithPool(b *testing.B) {
	ctx := context.Background()
	testEvents := createTestEvents(100)
	factory := NewPooledCodecFactory()
	
	b.ResetTimer()
	b.ReportAllocs()
	
	for i := 0; i < b.N; i++ {
		encoder, err := factory.CreateEncoder(ctx, "application/x-protobuf", &EncodingOptions{})
		if err != nil {
			b.Fatal(err)
		}
		
		for _, event := range testEvents {
			_, err := encoder.Encode(ctx, event)
			if err != nil {
				b.Fatal(err)
			}
		}
		
		if pooledEncoder, ok := encoder.(ReleasableEncoder); ok {
			pooledEncoder.Release()
		}
	}
}

// BenchmarkBufferPooling benchmarks buffer pooling
func BenchmarkBufferPooling(b *testing.B) {
	b.Run("WithoutPool", func(b *testing.B) {
		b.ReportAllocs()
		for i := 0; i < b.N; i++ {
			buf := make([]byte, 1024)
			_ = buf
		}
	})
	
	b.Run("WithPool", func(b *testing.B) {
		b.ReportAllocs()
		for i := 0; i < b.N; i++ {
			buf := GetBuffer(1024)
			PutBuffer(buf)
		}
	})
}

// BenchmarkSlicePooling benchmarks slice pooling
func BenchmarkSlicePooling(b *testing.B) {
	b.Run("WithoutPool", func(b *testing.B) {
		b.ReportAllocs()
		for i := 0; i < b.N; i++ {
			slice := make([]byte, 0, 1024)
			_ = slice
		}
	})
	
	b.Run("WithPool", func(b *testing.B) {
		b.ReportAllocs()
		for i := 0; i < b.N; i++ {
			slice := GetSlice(1024)
			PutSlice(slice)
		}
	})
}

// BenchmarkErrorPooling benchmarks error pooling
func BenchmarkErrorPooling(b *testing.B) {
	b.Run("WithoutPool", func(b *testing.B) {
		b.ReportAllocs()
		for i := 0; i < b.N; i++ {
			err := &EncodingError{
				Format:  "test",
				Message: "test error",
			}
			_ = err
		}
	})
	
	b.Run("WithPool", func(b *testing.B) {
		b.ReportAllocs()
		for i := 0; i < b.N; i++ {
			err := GetEncodingError()
			err.Format = "test"
			err.Message = "test error"
			PutEncodingError(err)
		}
	})
}

// BenchmarkHighThroughputScenario benchmarks a high-throughput scenario
func BenchmarkHighThroughputScenario(b *testing.B) {
	ctx := context.Background()
	testEvents := createTestEvents(1000)
	
	b.Run("WithoutPool", func(b *testing.B) {
		b.ReportAllocs()
		for i := 0; i < b.N; i++ {
			encoder := json.NewJSONEncoder(&EncodingOptions{})
			decoder := json.NewJSONDecoder(&DecodingOptions{})
			
			for _, event := range testEvents {
				data, err := encoder.Encode(ctx, event)
				if err != nil {
					b.Fatal(err)
				}
				_, err = decoder.Decode(ctx, data)
				if err != nil {
					b.Fatal(err)
				}
			}
		}
	})
	
	b.Run("WithPool", func(b *testing.B) {
		factory := NewPooledCodecFactory()
		b.ReportAllocs()
		
		for i := 0; i < b.N; i++ {
			encoder, err := factory.CreateEncoder(ctx, "application/json", &EncodingOptions{})
			if err != nil {
				b.Fatal(err)
			}
			decoder, err := factory.CreateDecoder(ctx, "application/json", &DecodingOptions{})
			if err != nil {
				b.Fatal(err)
			}
			
			for _, event := range testEvents {
				data, err := encoder.Encode(ctx, event)
				if err != nil {
					b.Fatal(err)
				}
				_, err = decoder.Decode(ctx, data)
				if err != nil {
					b.Fatal(err)
				}
			}
			
			if pooledEncoder, ok := encoder.(ReleasableEncoder); ok {
				pooledEncoder.Release()
			}
			if pooledDecoder, ok := decoder.(ReleasableDecoder); ok {
				pooledDecoder.Release()
			}
		}
	})
}

// BenchmarkGCPressure measures GC pressure with and without pooling
func BenchmarkGCPressure(b *testing.B) {
	ctx := context.Background()
	testEvents := createTestEvents(100)
	
	b.Run("WithoutPool", func(b *testing.B) {
		var m1, m2 runtime.MemStats
		runtime.GC()
		runtime.ReadMemStats(&m1)
		
		b.ResetTimer()
		for i := 0; i < b.N; i++ {
			encoder := json.NewJSONEncoder(&EncodingOptions{})
			for _, event := range testEvents {
				_, err := encoder.Encode(ctx, event)
				if err != nil {
					b.Fatal(err)
				}
			}
		}
		b.StopTimer()
		
		runtime.GC()
		runtime.ReadMemStats(&m2)
		
		b.ReportMetric(float64(m2.NumGC-m1.NumGC), "gc-runs")
		b.ReportMetric(float64(m2.PauseTotalNs-m1.PauseTotalNs)/1000000, "gc-pause-ms")
	})
	
	b.Run("WithPool", func(b *testing.B) {
		factory := NewPooledCodecFactory()
		var m1, m2 runtime.MemStats
		runtime.GC()
		runtime.ReadMemStats(&m1)
		
		b.ResetTimer()
		for i := 0; i < b.N; i++ {
			encoder, err := factory.CreateEncoder(ctx, "application/json", &EncodingOptions{})
			if err != nil {
				b.Fatal(err)
			}
			
			for _, event := range testEvents {
				_, err := encoder.Encode(ctx, event)
				if err != nil {
					b.Fatal(err)
				}
			}
			
			if pooledEncoder, ok := encoder.(ReleasableEncoder); ok {
				pooledEncoder.Release()
			}
		}
		b.StopTimer()
		
		runtime.GC()
		runtime.ReadMemStats(&m2)
		
		b.ReportMetric(float64(m2.NumGC-m1.NumGC), "gc-runs")
		b.ReportMetric(float64(m2.PauseTotalNs-m1.PauseTotalNs)/1000000, "gc-pause-ms")
	})
}

// BenchmarkConcurrentUsage benchmarks concurrent usage of pooled codecs
func BenchmarkConcurrentUsage(b *testing.B) {
	ctx := context.Background()
	testEvents := createTestEvents(50)
	factory := NewPooledCodecFactory()
	
	b.ResetTimer()
	b.ReportAllocs()
	
	b.RunParallel(func(pb *testing.PB) {
		for pb.Next() {
			encoder, err := factory.CreateEncoder(ctx, "application/json", &EncodingOptions{})
			if err != nil {
				b.Fatal(err)
			}
			
			for _, event := range testEvents {
				_, err := encoder.Encode(ctx, event)
				if err != nil {
					b.Fatal(err)
				}
			}
			
			if pooledEncoder, ok := encoder.(ReleasableEncoder); ok {
				pooledEncoder.Release()
			}
		}
	})
}

// TestPoolMetrics tests pool metrics collection
func TestPoolMetrics(t *testing.T) {
	ctx := context.Background()
	factory := NewPooledCodecFactory()
	
	// Create and use some encoders
	for i := 0; i < 10; i++ {
		encoder, err := factory.CreateEncoder(ctx, "application/json", &EncodingOptions{})
		if err != nil {
			t.Fatal(err)
		}
		
		event := &events.TextMessageContentEvent{
			BaseEvent: &events.BaseEvent{
				EventType: events.EventTypeTextMessageContent,
			},
			MessageID: "test",
			Delta:     "test content",
		}
		
		_, err = encoder.Encode(ctx, event)
		if err != nil {
			t.Fatal(err)
		}
		
		if pooledEncoder, ok := encoder.(ReleasableEncoder); ok {
			pooledEncoder.Release()
		}
	}
	
	// Check metrics
	metrics := factory.GetCodecPool().Metrics()
	if metrics.Gets == 0 {
		t.Error("Expected Gets > 0")
	}
	if metrics.Puts == 0 {
		t.Error("Expected Puts > 0")
	}
	if metrics.News == 0 {
		t.Error("Expected News > 0")
	}
	if metrics.Resets == 0 {
		t.Error("Expected Resets > 0")
	}
}

// TestPoolStats tests global pool statistics
func TestPoolStats(t *testing.T) {
	// Use some buffers and slices
	for i := 0; i < 5; i++ {
		buf := GetBuffer(1024)
		slice := GetSlice(1024)
		
		PutBuffer(buf)
		PutSlice(slice)
	}
	
	// Check stats
	stats := PoolStats()
	if len(stats) == 0 {
		t.Error("Expected non-empty stats")
	}
	
	// Check specific pool stats
	if smallBuf, ok := stats["small_buffer"]; ok {
		if smallBuf.Gets == 0 {
			t.Error("Expected small_buffer Gets > 0")
		}
	}
}

// TestPoolReset tests pool reset functionality
func TestPoolReset(t *testing.T) {
	// Use some resources
	buf := GetBuffer(1024)
	PutBuffer(buf)
	
	// Get initial stats
	stats := PoolStats()
	initialGets := stats["small_buffer"].Gets
	
	// Reset pools
	ResetAllPools()
	
	// Check stats are reset
	stats = PoolStats()
	if stats["small_buffer"].Gets != 0 {
		t.Error("Expected Gets to be 0 after reset")
	}
	
	// Use resources again
	buf = GetBuffer(1024)
	PutBuffer(buf)
	
	// Verify functionality still works
	stats = PoolStats()
	if stats["small_buffer"].Gets == 0 {
		t.Error("Expected Gets > 0 after using pool post-reset")
	}
}

// TestPoolManager tests the pool manager functionality
func TestPoolManager(t *testing.T) {
	pm := NewPoolManager()
	
	// Register some pools
	pm.RegisterPool("buffer", smallBufferPool)
	pm.RegisterPool("slice", smallSlicePool)
	
	// Test retrieval
	if pm.GetPool("buffer") == nil {
		t.Error("Expected to retrieve buffer pool")
	}
	
	// Test metrics
	metrics := pm.GetAllMetrics()
	if len(metrics) == 0 {
		t.Error("Expected non-empty metrics")
	}
	
	// Test monitoring
	ch := pm.StartMonitoring(10 * time.Millisecond)
	
	// Use some resources to generate metrics
	buf := GetBuffer(1024)
	PutBuffer(buf)
	
	// Wait for metrics
	select {
	case metrics := <-ch:
		if len(metrics) == 0 {
			t.Error("Expected non-empty metrics from monitoring")
		}
	case <-time.After(100 * time.Millisecond):
		t.Error("Timeout waiting for metrics")
	}
}