package transport

import (
	"context"
	"fmt"
	"sync"
	"time"

	"github.com/ag-ui/go-sdk/pkg/core"
	// "github.com/ag-ui/go-sdk/pkg/transport/capabilities"
	// "github.com/ag-ui/go-sdk/pkg/transport/config"
	// "github.com/ag-ui/go-sdk/pkg/transport/factory"
)

// Manager orchestrates transport operations including selection, failover, and load balancing
type Manager struct {
	mu              sync.RWMutex
	config          *config.Config
	registry        *factory.TransportRegistry
	factory         *factory.Factory
	activeTransport Transport
	fallbackQueue   []string
	connectionPool  *ConnectionPool
	healthMonitor   *HealthMonitor
	loadBalancer    *LoadBalancer
	middleware      []Middleware
	eventChan       chan Event
	errorChan       chan error
	stopChan        chan struct{}
	running         bool
	metrics         *ManagerMetrics
}

// ManagerMetrics contains metrics for the transport manager
type ManagerMetrics struct {
	mu                     sync.RWMutex
	TransportSwitches      uint64
	TotalConnections       uint64
	ActiveConnections      uint64
	FailedConnections      uint64
	TotalMessagesSent      uint64
	TotalMessagesReceived  uint64
	TotalBytesSent         uint64
	TotalBytesReceived     uint64
	AverageLatency         time.Duration
	LastTransportSwitch    time.Time
	TransportHealthScores  map[string]float64
	ConnectionPoolStats    ConnectionPoolStats
}

// NewManager creates a new transport manager
func NewManager(cfg *config.Config, registry *factory.TransportRegistry, factory *factory.Factory) *Manager {
	manager := &Manager{
		config:        cfg,
		registry:      registry,
		factory:       factory,
		connectionPool: NewConnectionPool(cfg),
		healthMonitor: NewHealthMonitor(cfg),
		loadBalancer:  NewLoadBalancer(cfg),
		middleware:    []Middleware{},
		eventChan:     make(chan Event, cfg.Global.BufferSize),
		errorChan:     make(chan error, cfg.Global.BufferSize),
		stopChan:      make(chan struct{}),
		metrics:       &ManagerMetrics{
			TransportHealthScores: make(map[string]float64),
		},
	}

	// Initialize fallback queue
	manager.fallbackQueue = make([]string, len(cfg.Fallback))
	copy(manager.fallbackQueue, cfg.Fallback)

	return manager
}

// Start starts the transport manager
func (m *Manager) Start(ctx context.Context) error {
	m.mu.Lock()
	defer m.mu.Unlock()

	if m.running {
		return fmt.Errorf("transport manager already running")
	}

	// Select initial transport
	if err := m.selectTransport(ctx); err != nil {
		return fmt.Errorf("failed to select initial transport: %w", err)
	}

	// Start health monitoring
	if err := m.healthMonitor.Start(ctx); err != nil {
		return fmt.Errorf("failed to start health monitor: %w", err)
	}

	// Start connection pool
	if err := m.connectionPool.Start(ctx); err != nil {
		return fmt.Errorf("failed to start connection pool: %w", err)
	}

	// Start event processing
	go m.eventProcessor(ctx)

	m.running = true
	return nil
}

// Stop stops the transport manager
func (m *Manager) Stop(ctx context.Context) error {
	m.mu.Lock()
	defer m.mu.Unlock()

	if !m.running {
		return nil
	}

	// Signal stop
	close(m.stopChan)

	// Drain event channels with timeout
	drainCtx, cancel := context.WithTimeout(ctx, 2*time.Second)
	defer cancel()
	
	// Create a wait group to track draining completion
	var wg sync.WaitGroup
	
	// Drain eventChan
	wg.Add(1)
	go func() {
		defer wg.Done()
		for {
			select {
			case <-m.eventChan:
				// Discard event but continue draining
			case <-drainCtx.Done():
				return
			}
		}
	}()
	
	// Drain errorChan
	wg.Add(1)
	go func() {
		defer wg.Done()
		for {
			select {
			case <-m.errorChan:
				// Discard error but continue draining
			case <-drainCtx.Done():
				return
			}
		}
	}()
	
	// Wait for draining to complete or timeout
	doneChan := make(chan struct{})
	go func() {
		wg.Wait()
		close(doneChan)
	}()
	
	select {
	case <-doneChan:
		// Draining completed successfully
	case <-drainCtx.Done():
		// Draining timed out, but we'll continue with shutdown
	}

	// Stop components
	if err := m.healthMonitor.Stop(); err != nil {
		return fmt.Errorf("failed to stop health monitor: %w", err)
	}

	if err := m.connectionPool.Stop(ctx); err != nil {
		return fmt.Errorf("failed to stop connection pool: %w", err)
	}

	// Close active transport
	if m.activeTransport != nil {
		if err := m.activeTransport.Close(ctx); err != nil {
			return fmt.Errorf("failed to close active transport: %w", err)
		}
	}

	m.running = false
	return nil
}

// Send sends an event through the active transport
func (m *Manager) Send(ctx context.Context, event core.Event) error {
	m.mu.RLock()
	transport := m.activeTransport
	m.mu.RUnlock()

	if transport == nil {
		return ErrNotConnected
	}

	// Apply middleware
	finalTransport := transport
	for i := len(m.middleware) - 1; i >= 0; i-- {
		finalTransport = m.middleware[i].Wrap(finalTransport)
	}

	// Send event
	err := finalTransport.Send(ctx, event)
	if err != nil {
		// Handle send error
		if m.shouldFailover(err) {
			go m.triggerFailover(ctx, err)
		}
		return err
	}

	// Update metrics
	m.updateSendMetrics()

	return nil
}

// Receive returns the event channel for receiving events
func (m *Manager) Receive() <-chan Event {
	return m.eventChan
}

// Errors returns the error channel
func (m *Manager) Errors() <-chan error {
	return m.errorChan
}

// GetActiveTransport returns the currently active transport
func (m *Manager) GetActiveTransport() Transport {
	m.mu.RLock()
	defer m.mu.RUnlock()
	return m.activeTransport
}

// GetMetrics returns the manager metrics
func (m *Manager) GetMetrics() ManagerMetrics {
	m.metrics.mu.RLock()
	defer m.metrics.mu.RUnlock()
	
	// Deep copy metrics
	metrics := *m.metrics
	metrics.TransportHealthScores = make(map[string]float64)
	for k, v := range m.metrics.TransportHealthScores {
		metrics.TransportHealthScores[k] = v
	}
	
	return metrics
}

// SwitchTransport manually switches to a specific transport
func (m *Manager) SwitchTransport(ctx context.Context, transportType string) error {
	m.mu.Lock()
	defer m.mu.Unlock()

	if !m.registry.HasTransport(transportType) {
		return fmt.Errorf("transport type %s not available", transportType)
	}

	return m.switchToTransport(ctx, transportType)
}

// AddMiddleware adds middleware to the transport stack
func (m *Manager) AddMiddleware(middleware ...Middleware) {
	m.mu.Lock()
	defer m.mu.Unlock()

	m.middleware = append(m.middleware, middleware...)
}

// selectTransport selects the best transport based on configuration
func (m *Manager) selectTransport(ctx context.Context) error {
	requirements := factory.Requirements{
		Streaming:           contains(m.config.Capabilities.Required, "streaming"),
		Bidirectional:      contains(m.config.Capabilities.Required, "bidirectional"),
		Compression:        contains(m.config.Capabilities.Required, "compression"),
		Multiplexing:       contains(m.config.Capabilities.Required, "multiplexing"),
		Reconnection:       contains(m.config.Capabilities.Required, "reconnection"),
		MaxLatency:         m.config.Performance.LatencyThreshold,
		MinThroughput:      m.config.Performance.ThroughputThreshold,
		PreferredTransports: []string{m.config.Primary},
	}

	transportType, err := m.registry.SelectTransport(ctx, requirements)
	if err != nil {
		return fmt.Errorf("failed to select transport: %w", err)
	}

	return m.switchToTransport(ctx, transportType)
}

// switchToTransport switches to a specific transport
func (m *Manager) switchToTransport(ctx context.Context, transportType string) error {
	// Get transport configuration
	var transportConfig interface{}
	if m.config.Transports != nil {
		transportConfig = m.config.Transports[transportType]
	}

	// Create new transport
	newTransport, err := m.registry.CreateTransport(ctx, transportType, transportConfig)
	if err != nil {
		return fmt.Errorf("failed to create transport %s: %w", transportType, err)
	}

	// Apply middleware
	finalTransport := newTransport
	for i := len(m.middleware) - 1; i >= 0; i-- {
		finalTransport = m.middleware[i].Wrap(finalTransport)
	}

	// Connect new transport
	if err := finalTransport.Connect(ctx); err != nil {
		return fmt.Errorf("failed to connect transport %s: %w", transportType, err)
	}

	// Close old transport
	if m.activeTransport != nil {
		// Use a timeout context for closing old transport
		closeCtx, cancel := context.WithTimeout(ctx, 5*time.Second)
		defer cancel()
		if err := m.activeTransport.Close(closeCtx); err != nil {
			// Log error but don't fail the switch
			fmt.Printf("Warning: failed to close old transport: %v\n", err)
		}
	}

	// Set new active transport
	m.activeTransport = finalTransport

	// Update metrics
	m.updateSwitchMetrics(transportType)

	// Start receiving events from new transport
	go m.receiveEvents(finalTransport)

	return nil
}

// receiveEvents receives events from a transport
func (m *Manager) receiveEvents(transport Transport) {
	for {
		select {
		case event := <-transport.Receive():
			select {
			case m.eventChan <- event:
			case <-m.stopChan:
				return
			}
		case err := <-transport.Errors():
			select {
			case m.errorChan <- err:
			case <-m.stopChan:
				return
			}
			
			// Handle error
			if m.shouldFailover(err) {
				go m.triggerFailover(context.Background(), err)
			}
		case <-m.stopChan:
			return
		}
	}
}

// eventProcessor processes events and errors
func (m *Manager) eventProcessor(ctx context.Context) {
	ticker := time.NewTicker(time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-ctx.Done():
			return
		case <-m.stopChan:
			return
		case <-ticker.C:
			// Update metrics periodically
			m.updatePeriodicMetrics()
		}
	}
}

// shouldFailover determines if an error should trigger failover
func (m *Manager) shouldFailover(err error) bool {
	// Check if error is a transport error
	if te, ok := err.(*TransportError); ok {
		return !te.IsRetryable() || te.IsTemporary()
	}

	// Check specific error types
	switch err {
	case ErrConnectionClosed, ErrConnectionFailed, ErrHealthCheckFailed:
		return true
	default:
		return false
	}
}

// triggerFailover triggers a failover to the next available transport
func (m *Manager) triggerFailover(ctx context.Context, triggerError error) {
	m.mu.Lock()
	defer m.mu.Unlock()

	if len(m.fallbackQueue) == 0 {
		m.errorChan <- fmt.Errorf("no fallback transports available: %w", triggerError)
		return
	}

	// Try each fallback transport
	for _, transportType := range m.fallbackQueue {
		if err := m.switchToTransport(ctx, transportType); err == nil {
			// Successful failover
			fmt.Printf("Successfully failed over to transport: %s\n", transportType)
			return
		}
	}

	// All fallbacks failed
	m.errorChan <- fmt.Errorf("all fallback transports failed: %w", triggerError)
}

// updateSendMetrics updates send-related metrics
func (m *Manager) updateSendMetrics() {
	m.metrics.mu.Lock()
	defer m.metrics.mu.Unlock()

	m.metrics.TotalMessagesSent++
}

// updateSwitchMetrics updates transport switch metrics
func (m *Manager) updateSwitchMetrics(transportType string) {
	m.metrics.mu.Lock()
	defer m.metrics.mu.Unlock()

	m.metrics.TransportSwitches++
	m.metrics.LastTransportSwitch = time.Now()
}

// updatePeriodicMetrics updates metrics that are calculated periodically
func (m *Manager) updatePeriodicMetrics() {
	m.metrics.mu.Lock()
	defer m.metrics.mu.Unlock()

	// Update connection pool stats
	if m.connectionPool != nil {
		m.metrics.ConnectionPoolStats = m.connectionPool.GetStats()
	}

	// Update transport health scores
	if m.healthMonitor != nil {
		m.metrics.TransportHealthScores = m.healthMonitor.GetHealthScores()
	}

	// Update active transport metrics
	if m.activeTransport != nil {
		transportMetrics := m.activeTransport.Metrics()
		m.metrics.TotalMessagesReceived += transportMetrics.MessagesReceived
		m.metrics.TotalBytesSent += transportMetrics.BytesSent
		m.metrics.TotalBytesReceived += transportMetrics.BytesReceived
		m.metrics.AverageLatency = transportMetrics.AverageLatency
	}
}

// contains checks if a slice contains a value
func contains(slice []string, value string) bool {
	for _, item := range slice {
		if item == value {
			return true
		}
	}
	return false
}

// ConnectionPool manages a pool of transport connections
type ConnectionPool struct {
	mu          sync.RWMutex
	config      *config.Config
	connections map[string][]Transport
	stats       ConnectionPoolStats
}

// ConnectionPoolStats contains statistics about the connection pool
type ConnectionPoolStats struct {
	TotalConnections   int
	ActiveConnections  int
	IdleConnections    int
	ConnectionsCreated uint64
	ConnectionsReused  uint64
	ConnectionsRemoved uint64
}

// NewConnectionPool creates a new connection pool
func NewConnectionPool(cfg *config.Config) *ConnectionPool {
	return &ConnectionPool{
		config:      cfg,
		connections: make(map[string][]Transport),
		stats:       ConnectionPoolStats{},
	}
}

// Start starts the connection pool
func (cp *ConnectionPool) Start(ctx context.Context) error {
	// Initialize connection pool
	return nil
}

// Stop stops the connection pool
func (cp *ConnectionPool) Stop(ctx context.Context) error {
	cp.mu.Lock()
	defer cp.mu.Unlock()

	// Close all connections
	for _, transports := range cp.connections {
		for _, transport := range transports {
			transport.Close(ctx)
		}
	}

	cp.connections = make(map[string][]Transport)
	return nil
}

// GetStats returns connection pool statistics
func (cp *ConnectionPool) GetStats() ConnectionPoolStats {
	cp.mu.RLock()
	defer cp.mu.RUnlock()
	return cp.stats
}

// HealthMonitor monitors transport health
type HealthMonitor struct {
	mu           sync.RWMutex
	config       *config.Config
	healthScores map[string]float64
	running      bool
}

// NewHealthMonitor creates a new health monitor
func NewHealthMonitor(cfg *config.Config) *HealthMonitor {
	return &HealthMonitor{
		config:       cfg,
		healthScores: make(map[string]float64),
	}
}

// Start starts the health monitor
func (hm *HealthMonitor) Start(ctx context.Context) error {
	hm.mu.Lock()
	defer hm.mu.Unlock()

	if hm.running {
		return fmt.Errorf("health monitor already running")
	}

	// Start health monitoring
	go hm.monitorHealth(ctx)

	hm.running = true
	return nil
}

// Stop stops the health monitor
func (hm *HealthMonitor) Stop() error {
	hm.mu.Lock()
	defer hm.mu.Unlock()

	hm.running = false
	return nil
}

// GetHealthScores returns health scores for all transports
func (hm *HealthMonitor) GetHealthScores() map[string]float64 {
	hm.mu.RLock()
	defer hm.mu.RUnlock()

	scores := make(map[string]float64)
	for k, v := range hm.healthScores {
		scores[k] = v
	}
	return scores
}

// monitorHealth monitors transport health
func (hm *HealthMonitor) monitorHealth(ctx context.Context) {
	ticker := time.NewTicker(hm.config.Selection.HealthCheckInterval)
	defer ticker.Stop()

	for {
		select {
		case <-ctx.Done():
			return
		case <-ticker.C:
			// Perform health checks
			hm.performHealthChecks(ctx)
		}
	}
}

// performHealthChecks performs health checks on all transports
func (hm *HealthMonitor) performHealthChecks(ctx context.Context) {
	// This would implement actual health checking logic
	// For now, this is a placeholder
}

// LoadBalancer handles load balancing across multiple transports
type LoadBalancer struct {
	mu       sync.RWMutex
	config   *config.Config
	strategy LoadBalanceStrategy
}

// LoadBalanceStrategy defines load balancing behavior
type LoadBalanceStrategy interface {
	SelectTransport(available []string, healthScores map[string]float64) (string, error)
}

// NewLoadBalancer creates a new load balancer
func NewLoadBalancer(cfg *config.Config) *LoadBalancer {
	var strategy LoadBalanceStrategy

	switch cfg.Selection.LoadBalancing.Strategy {
	case "round_robin":
		strategy = &RoundRobinStrategy{}
	case "least_connections":
		strategy = &LeastConnectionsStrategy{}
	case "random":
		strategy = &RandomStrategy{}
	case "weighted":
		strategy = &WeightedStrategy{weights: cfg.Selection.LoadBalancing.Weights}
	default:
		strategy = &RoundRobinStrategy{}
	}

	return &LoadBalancer{
		config:   cfg,
		strategy: strategy,
	}
}

// RoundRobinStrategy implements round-robin load balancing
type RoundRobinStrategy struct {
	current int
}

func (s *RoundRobinStrategy) SelectTransport(available []string, healthScores map[string]float64) (string, error) {
	if len(available) == 0 {
		return "", fmt.Errorf("no available transports")
	}

	selected := available[s.current%len(available)]
	s.current++
	return selected, nil
}

// LeastConnectionsStrategy implements least connections load balancing
type LeastConnectionsStrategy struct{}

func (s *LeastConnectionsStrategy) SelectTransport(available []string, healthScores map[string]float64) (string, error) {
	if len(available) == 0 {
		return "", fmt.Errorf("no available transports")
	}

	// For now, just return the first available
	// In a real implementation, this would track connection counts
	return available[0], nil
}

// RandomStrategy implements random load balancing
type RandomStrategy struct{}

func (s *RandomStrategy) SelectTransport(available []string, healthScores map[string]float64) (string, error) {
	if len(available) == 0 {
		return "", fmt.Errorf("no available transports")
	}

	// For now, just return the first available
	// In a real implementation, this would use random selection
	return available[0], nil
}

// WeightedStrategy implements weighted load balancing
type WeightedStrategy struct {
	weights map[string]int
}

func (s *WeightedStrategy) SelectTransport(available []string, healthScores map[string]float64) (string, error) {
	if len(available) == 0 {
		return "", fmt.Errorf("no available transports")
	}

	// For now, just return the first available
	// In a real implementation, this would use weighted selection
	return available[0], nil
}