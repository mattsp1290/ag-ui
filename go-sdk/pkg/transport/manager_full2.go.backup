package transport

import (
	"context"
	"fmt"
	"sync"
	"time"
)

// Config represents simplified transport configuration
type Config struct {
	Primary       string
	Fallback      []string
	BufferSize    int
	LogLevel      string
	EnableMetrics bool
	Backpressure  BackpressureConfig
}

// Manager orchestrates transport operations including selection, failover, and load balancing
type Manager struct {
	mu                  sync.RWMutex
	config              *Config
	activeTransport     Transport
	fallbackQueue       []string
	middleware          []Middleware
	eventChan           chan Event
	errorChan           chan error
	stopChan            chan struct{}
	running             bool
	metrics             *ManagerMetrics
	logger              Logger
	backpressureHandler *BackpressureHandler
}

// ManagerMetrics contains metrics for the transport manager
type ManagerMetrics struct {
	mu                     sync.RWMutex
	TransportSwitches      uint64
	TotalConnections       uint64
	ActiveConnections      uint64
	FailedConnections      uint64
	TotalMessagesSent      uint64
	TotalMessagesReceived  uint64
	TotalBytesSent         uint64
	TotalBytesReceived     uint64
	AverageLatency         time.Duration
	LastTransportSwitch    time.Time
	TransportHealthScores  map[string]float64
}

// NewManager creates a new transport manager
func NewManager(cfg *Config) *Manager {
	if cfg == nil {
		cfg = &Config{
			Primary:     "websocket",
			Fallback:    []string{"sse", "http"},
			BufferSize:  1024,
			LogLevel:    "info",
			EnableMetrics: true,
			Backpressure: BackpressureConfig{
				Strategy:      BackpressureNone,
				BufferSize:    1024,
				HighWaterMark: 0.8,
				LowWaterMark:  0.2,
				BlockTimeout:  5 * time.Second,
				EnableMetrics: true,
			},
		}
	}
	
	manager := &Manager{
		config:        cfg,
		middleware:    []Middleware{},
		eventChan:     make(chan Event, cfg.BufferSize),
		errorChan:     make(chan error, cfg.BufferSize),
		stopChan:      make(chan struct{}),
		metrics:       &ManagerMetrics{
			TransportHealthScores: make(map[string]float64),
		},
		logger:        NewNoopLogger(),
	}
	
	// Initialize backpressure handler
	manager.backpressureHandler = NewBackpressureHandler(cfg.Backpressure)

	// Initialize fallback queue
	manager.fallbackQueue = make([]string, len(cfg.Fallback))
	copy(manager.fallbackQueue, cfg.Fallback)

	return manager
}

// NewManagerWithLogger creates a new transport manager with a custom logger
func NewManagerWithLogger(cfg *Config, logger Logger) *Manager {
	manager := NewManager(cfg)
	if logger != nil {
		manager.logger = logger
	}
	return manager
}

// Start starts the transport manager
func (m *Manager) Start(ctx context.Context) error {
	m.mu.Lock()
	defer m.mu.Unlock()

	m.logger.Info("Starting transport manager", 
		String("operation", "start"),
		String("primary_transport", m.config.Primary),
		Int("fallback_count", len(m.fallbackQueue)))

	if m.running {
		m.logger.Warn("Attempted to start already running manager", 
			String("operation", "start"))
		return fmt.Errorf("transport manager already running")
	}

	// Start event processing
	go m.eventProcessor(ctx)

	m.running = true
	m.logger.Info("Transport manager started successfully", 
		String("operation", "start"))
	
	return nil
}

// Stop stops the transport manager
func (m *Manager) Stop(ctx context.Context) error {
	m.mu.Lock()
	defer m.mu.Unlock()

	m.logger.Info("Stopping transport manager", 
		String("operation", "stop"))

	if !m.running {
		m.logger.Debug("Manager already stopped", 
			String("operation", "stop"))
		return nil
	}

	// Signal stop
	close(m.stopChan)

	// Drain event channels with timeout
	drainCtx, cancel := context.WithTimeout(ctx, 2*time.Second)
	defer cancel()
	
	m.logger.Debug("Draining event channels", 
		String("operation", "stop"),
		Duration("timeout", 2*time.Second))

	// Create a wait group to track draining completion
	var wg sync.WaitGroup
	
	// Drain eventChan
	wg.Add(1)
	go func() {
		defer wg.Done()
		eventCount := 0
		for {
			select {
			case <-m.eventChan:
				eventCount++
				// Discard event but continue draining
			case <-drainCtx.Done():
				if eventCount > 0 {
					m.logger.Debug("Drained events from event channel", 
						String("operation", "stop"),
						Int("events_drained", eventCount))
				}
				return
			}
		}
	}()
	
	// Drain errorChan
	wg.Add(1)
	go func() {
		defer wg.Done()
		errorCount := 0
		for {
			select {
			case <-m.errorChan:
				errorCount++
				// Discard error but continue draining
			case <-drainCtx.Done():
				if errorCount > 0 {
					m.logger.Debug("Drained errors from error channel", 
						String("operation", "stop"),
						Int("errors_drained", errorCount))
				}
				return
			}
		}
	}()
	
	// Wait for draining to complete or timeout
	doneChan := make(chan struct{})
	go func() {
		wg.Wait()
		close(doneChan)
	}()
	
	select {
	case <-doneChan:
		m.logger.Debug("Channel draining completed successfully", 
			String("operation", "stop"))
	case <-drainCtx.Done():
		m.logger.Warn("Channel draining timed out", 
			String("operation", "stop"))
	}

	// Close active transport
	if m.activeTransport != nil {
		m.logger.Info("Closing active transport", 
			String("operation", "stop"))
		
		if err := m.activeTransport.Close(ctx); err != nil {
			m.logger.Error("Failed to close active transport", 
				String("operation", "stop"),
				Error(err))
			return fmt.Errorf("failed to close active transport: %w", err)
		}
		
		m.logger.Debug("Active transport closed successfully", 
			String("operation", "stop"))
	}

	// Stop backpressure handler
	if m.backpressureHandler != nil {
		m.backpressureHandler.Stop()
		m.logger.Debug("Backpressure handler stopped", 
			String("operation", "stop"))
	}

	m.running = false
	m.logger.Info("Transport manager stopped successfully", 
		String("operation", "stop"))
	
	return nil
}

// Send sends an event through the active transport
func (m *Manager) Send(ctx context.Context, event TransportEvent) error {
	m.mu.RLock()
	transport := m.activeTransport
	m.mu.RUnlock()

	if transport == nil {
		m.logger.Error("Cannot send event: no active transport", 
			String("operation", "send"),
			String("event_id", event.ID()),
			String("event_type", event.Type()))
		return ErrNotConnected
	}

	// Apply middleware
	finalTransport := transport
	for i := len(m.middleware) - 1; i >= 0; i-- {
		finalTransport = m.middleware[i].Wrap(finalTransport)
	}

	m.logger.Debug("Sending event through transport", 
		String("operation", "send"),
		String("event_id", event.ID()),
		String("event_type", event.Type()),
		Int("middleware_count", len(m.middleware)))

	start := time.Now()
	
	// Send event
	err := finalTransport.Send(ctx, event)
	duration := time.Since(start)
	
	if err != nil {
		m.logger.Error("Failed to send event", 
			String("operation", "send"),
			String("event_id", event.ID()),
			String("event_type", event.Type()),
			Duration("duration", duration),
			Error(err))
		
		// Handle send error
		if m.shouldFailover(err) {
			m.logger.Warn("Triggering failover due to send error", 
				String("operation", "send"),
				Error(err))
			go m.triggerFailover(ctx, err)
		}
		return err
	}

	m.logger.Debug("Event sent successfully", 
		String("operation", "send"),
		String("event_id", event.ID()),
		String("event_type", event.Type()),
		Duration("duration", duration))

	// Update metrics
	m.updateSendMetrics()

	return nil
}

// Receive returns the event channel for receiving events
func (m *Manager) Receive() <-chan Event {
	if m.backpressureHandler != nil {
		return m.backpressureHandler.EventChan()
	}
	return m.eventChan
}

// Errors returns the error channel
func (m *Manager) Errors() <-chan error {
	if m.backpressureHandler != nil {
		return m.backpressureHandler.ErrorChan()
	}
	return m.errorChan
}

// GetActiveTransport returns the currently active transport
func (m *Manager) GetActiveTransport() Transport {
	m.mu.RLock()
	defer m.mu.RUnlock()
	return m.activeTransport
}

// GetBackpressureMetrics returns the current backpressure metrics
func (m *Manager) GetBackpressureMetrics() BackpressureMetrics {
	if m.backpressureHandler != nil {
		return m.backpressureHandler.GetMetrics()
	}
	return BackpressureMetrics{}
}

// GetMetrics returns the manager metrics
func (m *Manager) GetMetrics() ManagerMetrics {
	m.metrics.mu.RLock()
	defer m.metrics.mu.RUnlock()
	
	// Deep copy metrics
	metrics := *m.metrics
	metrics.TransportHealthScores = make(map[string]float64)
	for k, v := range m.metrics.TransportHealthScores {
		metrics.TransportHealthScores[k] = v
	}
	
	return metrics
}

// SetTransport sets the active transport
func (m *Manager) SetTransport(transport Transport) {
	m.mu.Lock()
	defer m.mu.Unlock()
	
	oldTransport := m.activeTransport
	
	if oldTransport != nil {
		m.logger.Info("Switching from old transport to new transport", 
			String("operation", "set_transport"))
		
		// Use a default timeout context for closing the old transport
		ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
		defer cancel()
		
		if err := oldTransport.Close(ctx); err != nil {
			m.logger.Error("Failed to close old transport", 
				String("operation", "set_transport"),
				Error(err))
		} else {
			m.logger.Debug("Old transport closed successfully", 
				String("operation", "set_transport"))
		}
	}
	
	m.activeTransport = transport
	
	if transport != nil {
		m.logger.Info("New transport set successfully", 
			String("operation", "set_transport"))
		
		// Start receiving events from new transport
		go m.receiveEvents(transport)
	} else {
		m.logger.Info("Transport set to nil", 
			String("operation", "set_transport"))
	}
}

// AddMiddleware adds middleware to the transport stack
func (m *Manager) AddMiddleware(middleware ...Middleware) {
	m.mu.Lock()
	defer m.mu.Unlock()

	m.logger.Info("Adding middleware to transport stack", 
		String("operation", "add_middleware"),
		Int("middleware_count", len(middleware)))

	m.middleware = append(m.middleware, middleware...)
}

// receiveEvents receives events from a transport
func (m *Manager) receiveEvents(transport Transport) {
	m.logger.Debug("Starting event receiver for transport", 
		String("operation", "receive_events"))
	
	defer m.logger.Debug("Event receiver stopped for transport", 
		String("operation", "receive_events"))

	for {
		select {
		case event := <-transport.Receive():
			m.logger.Debug("Received event from transport", 
				String("operation", "receive_events"),
				String("event_id", event.Event.ID()),
				String("event_type", event.Event.Type()))
			
			// Use backpressure handler to send event
			if err := m.backpressureHandler.SendEvent(event); err != nil {
				m.logger.Warn("Failed to send event due to backpressure", 
					String("operation", "receive_events"),
					String("event_id", event.Event.ID()),
					Error(err))
			} else {
				m.logger.Debug("Event forwarded to event channel", 
					String("operation", "receive_events"),
					String("event_id", event.Event.ID()))
			}
		case err := <-transport.Errors():
			m.logger.Error("Received error from transport", 
				String("operation", "receive_events"),
				Error(err))
			
			// Use backpressure handler to send error
			if sendErr := m.backpressureHandler.SendError(err); sendErr != nil {
				m.logger.Warn("Failed to send error due to backpressure", 
					String("operation", "receive_events"),
					Error(err),
					Any("send_error", sendErr))
			} else {
				m.logger.Debug("Error forwarded to error channel", 
					String("operation", "receive_events"))
			}
			
			// Handle error
			if m.shouldFailover(err) {
				m.logger.Warn("Triggering failover due to transport error", 
					String("operation", "receive_events"),
					Error(err))
				go m.triggerFailover(context.Background(), err)
			}
		case <-m.stopChan:
			m.logger.Debug("Stop signal received in event receiver", 
				String("operation", "receive_events"))
			return
		}
	}
}

// eventProcessor processes events and errors
func (m *Manager) eventProcessor(ctx context.Context) {
	m.logger.Debug("Starting event processor", 
		String("operation", "event_processor"))
	
	defer m.logger.Debug("Event processor stopped", 
		String("operation", "event_processor"))

	ticker := time.NewTicker(time.Second)
	defer ticker.Stop()

	for {
		select {
		case <-ctx.Done():
			m.logger.Debug("Context cancelled in event processor", 
				String("operation", "event_processor"))
			return
		case <-m.stopChan:
			m.logger.Debug("Stop signal received in event processor", 
				String("operation", "event_processor"))
			return
		case <-ticker.C:
			// Update metrics periodically
			m.updatePeriodicMetrics()
		}
	}
}

// shouldFailover determines if an error should trigger failover
func (m *Manager) shouldFailover(err error) bool {
	// Check if error is a transport error
	if te, ok := err.(*TransportError); ok {
		shouldFailover := !te.IsRetryable() || te.IsTemporary()
		m.logger.Debug("Evaluating failover for transport error", 
			String("operation", "should_failover"),
			Bool("should_failover", shouldFailover),
			Bool("is_retryable", te.IsRetryable()),
			Bool("is_temporary", te.IsTemporary()),
			Error(err))
		return shouldFailover
	}

	// Check specific error types
	switch err {
	case ErrConnectionClosed, ErrConnectionFailed, ErrHealthCheckFailed:
		m.logger.Debug("Failover recommended for connection error", 
			String("operation", "should_failover"),
			Error(err))
		return true
	default:
		m.logger.Debug("No failover recommended for error", 
			String("operation", "should_failover"),
			Error(err))
		return false
	}
}

// triggerFailover triggers a failover to the next available transport
func (m *Manager) triggerFailover(ctx context.Context, triggerError error) {
	m.mu.Lock()
	defer m.mu.Unlock()

	m.logger.Warn("Triggering failover", 
		String("operation", "trigger_failover"),
		Int("fallback_count", len(m.fallbackQueue)),
		Error(triggerError))

	if len(m.fallbackQueue) == 0 {
		m.logger.Error("No fallback transports available", 
			String("operation", "trigger_failover"),
			Error(triggerError))
		
		m.errorChan <- fmt.Errorf("no fallback transports available: %w", triggerError)
		return
	}

	// Try each fallback transport
	for i, transportType := range m.fallbackQueue {
		m.logger.Info("Attempting failover to transport", 
			String("operation", "trigger_failover"),
			String("transport_type", transportType),
			Int("attempt", i+1),
			Int("total_fallbacks", len(m.fallbackQueue)))
		
		if err := m.switchToTransport(ctx, transportType); err == nil {
			// Successful failover
			m.logger.Info("Successfully failed over to transport", 
				String("operation", "trigger_failover"),
				String("transport_type", transportType))
			return
		} else {
			m.logger.Error("Failed to switch to fallback transport", 
				String("operation", "trigger_failover"),
				String("transport_type", transportType),
				Error(err))
		}
	}

	// All fallbacks failed
	m.logger.Error("All fallback transports failed", 
		String("operation", "trigger_failover"),
		Error(triggerError))
	m.errorChan <- fmt.Errorf("all fallback transports failed: %w", triggerError)
}

// switchToTransport switches to a specific transport (simplified version)
func (m *Manager) switchToTransport(ctx context.Context, transportType string) error {
	m.logger.Info("Switching to transport", 
		String("operation", "switch_transport"),
		String("transport_type", transportType))

	// This is a simplified version - in a real implementation,
	// this would create the transport using a factory
	// For now, we'll just return an error to indicate the switch failed
	return fmt.Errorf("transport switching not implemented for type: %s", transportType)
}

// updateSendMetrics updates send-related metrics
func (m *Manager) updateSendMetrics() {
	m.metrics.mu.Lock()
	defer m.metrics.mu.Unlock()

	m.metrics.TotalMessagesSent++
	
	m.logger.Debug("Updated send metrics", 
		String("operation", "update_send_metrics"),
		Int64("total_messages_sent", int64(m.metrics.TotalMessagesSent)))
}

// updatePeriodicMetrics updates metrics that are calculated periodically
func (m *Manager) updatePeriodicMetrics() {
	m.metrics.mu.Lock()
	defer m.metrics.mu.Unlock()

	// Update active transport metrics
	if m.activeTransport != nil {
		transportMetrics := m.activeTransport.Metrics()
		m.metrics.TotalMessagesReceived += transportMetrics.MessagesReceived
		m.metrics.TotalBytesSent += transportMetrics.BytesSent
		m.metrics.TotalBytesReceived += transportMetrics.BytesReceived
		m.metrics.AverageLatency = transportMetrics.AverageLatency
		
		m.logger.Debug("Updated periodic metrics", 
			String("operation", "update_periodic_metrics"),
			Int64("messages_received", int64(transportMetrics.MessagesReceived)),
			Int64("bytes_sent", int64(transportMetrics.BytesSent)),
			Int64("bytes_received", int64(transportMetrics.BytesReceived)),
			Duration("average_latency", transportMetrics.AverageLatency))
	}
}

// SetLogger sets the logger for the manager
func (m *Manager) SetLogger(logger Logger) {
	m.mu.Lock()
	defer m.mu.Unlock()
	
	if logger == nil {
		logger = NewNoopLogger()
	}
	
	m.logger = logger
	m.logger.Info("Logger updated for Manager", 
		String("operation", "set_logger"))
}

// GetLogger returns the current logger
func (m *Manager) GetLogger() Logger {
	m.mu.RLock()
	defer m.mu.RUnlock()
	return m.logger
}